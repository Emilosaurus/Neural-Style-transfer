
# ğŸ¨ Neural Style Transfer in PyTorch

This project implements **Neural Style Transfer** to apply the artistic style of one image (style) to a set of content images using PyTorch. It supports **training from scratch** and works with **custom image inputs**.

---

## ğŸ§‘â€ğŸ’» Intern Details

**Company:** CODTECH IT SOLUTIONS  
**Name:** Emil Saj Abraham  
**Intern ID:** CT08DL252  
**Domain:** AI  
**Duration:** 8 weeks  
**Mentor:** Neela Santhosh  

---

## ğŸ“¸ Sample Result

<table>
  <tr>
    <th>Content Image</th>
    <th>Style Image</th>
    <th>Stylized Output</th>
  </tr>
  <tr>
    <td><img src="https://github.com/user-attachments/assets/8750739d-8d67-4c87-b6c6-5f2c89c674ee" width="200"/></td>
    <td><img src="https://github.com/user-attachments/assets/ed25c4ee-93bc-4691-b5c2-ac2f4709b27e" width="200"/></td>
    <td><img src="https://github.com/user-attachments/assets/da54f9da-0621-419a-b166-8a77b69bf4ce" width="200"/></td>
  </tr>
</table>



---

## ğŸ§° Requirements

Install the required Python packages:

```bash
pip install torch torchvision matplotlib pillow
```

Recommended to use a virtual environment (`venv`, `conda`, etc).

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ style_transfer.ipynb      # Main Jupyter Notebook
â”œâ”€â”€ style-image/
â”‚   â””â”€â”€ images.jpg            # Artistic style image
â”œâ”€â”€ input-image/
â”‚   â”œâ”€â”€ image1.jpg            # Content images
â”‚   â””â”€â”€ image2.jpg
â””â”€â”€ output/
    â”œâ”€â”€ styled_image1.jpg
    â””â”€â”€ styled_image2.jpg
```

---

## ğŸ§  Model

Uses **VGG-19** pretrained on ImageNet as the feature extractor. The loss is a weighted combination of:

- **Content Loss (MSE):** Preserves structure of input image.
- **Style Loss (Gram Matrix MSE):** Matches style features.

---

## ğŸš€ Usage

### Run in a Python script or Jupyter Notebook:

```python
# Load style image
style_img = load_image("style-image/images.jpg")

# Load and loop through all content images
content_dir = "/kaggle/input/input-image"
for fname in os.listdir(content_dir):
    content_img = load_image(os.path.join(content_dir, fname))
    input_img = content_img.clone()

    # Run Style Transfer
    output = run_style_transfer(cnn, cnn_normalization_mean, cnn_normalization_std,
                                content_img, style_img, input_img)

    # Save result
    save_image(output, f"output/styled_{fname}")
```

---

## ğŸ“Š Loss Behavior

- Style Loss reduces rapidly and plateaus â†’ style captured early.
- Content Loss gradually decreases â†’ structure preserved.

| Step | Style Loss | Content Loss |
|------|------------|--------------|
| 50   | 0.000077   | 19.384       |
| 500  | 0.000001   | 10.857       |
| 1000 | 0.000001   | 10.116       |

> ğŸŸ¢ Model convergence is smooth and balanced.

---

## ğŸ“„ License

MIT License â€” free to use, modify, and distribute.
